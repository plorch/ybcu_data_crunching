---
title: "ybcu_detectionFinal"
author: "Patrick D. lorch"
date: "2023-02-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Ownership

Data and analyses were collected and developed by Southern Sierra Research Station (SSRS).  They can be used freely by partners in the Lower Colorado River Multi-Species Conservation Program and Beureau of Reclamation staff.  Any other uses are allowed only with written permission from SSRS Director of Research (Mary Whitfield mailto:maryw@southernsierraresearch.org)

## Note

This file should only be used to recreate the analysis in the final 2022 report. If you are starting a new analysis, use the working folder not the Final folder. The original input file from John Stanek and Shannon McNeil has several variables that were not used in this final model.  Values for those variables were not derived for 2019-2022, and should be.

## History

This model is a generalized linear mixed effects model like the one done in 2018 by John Stanek and Shannon McNeil.  That modeling effort settled on model with site age and size for the final report.  



## Packages and functions
```{r functions}
library(readxl)
library(lme4)       # for glmer
library(car)
library(MASS)
library(MuMIn)   # for AICc function, R2 (r.squaredGLMM(R4))
library(dplyr)
library(tidyr)
library(AICcmodavg)

#  library(AED)  #This package is no longer available by Highstat Statistics, 
#     It is a set of functions used in data visualization (such as corvif() below) and exploration
# John copied the AED functions into a new file and we use it to call the functions
if(!exists("AED_functions.R", mode="function")) source("AED_functions.R")

### to plot figures
library(jtools)
library(ggplot2)
library(sjstats)
library(sjPlot)

```


## Old data

Bring in old data.

Data Description:
* Area (factor)
* Site (factor)
* Year (factor)
* Age (of the patch in years since planted, integer)
* dph (detections per hectare, numeric)
* contig (is the patch contiguous with another patch?, integer)
* big (is the patch within a large planted area (>100 ha)?, integer)
* svdets (number of survey detections of cuckoos, integer)
* nests (number of nests found, integer)
* ha (size of the patch of that age in hectares, numeric)
* cha (size of the contiguous patch, numeric)
* cha2 (size of the contiguous patch - treating PVER as 1 contiguous patch, numeric)
* inc (include in analysis? 1=yes, factor)
* youngest (is this patch the youngest patch around?, factor)
* nAges (number of different ages of patches within the contiguous patch, integer)
* nAges2 (nAges - but treat ages > 5 years as the same age, integer)
* tp20h (estimated territories per 20 hectares)
* PO PR CO (possible, probable and confirmed breeding territories, integer)
* ptd (probable territory density: (PR + CO only)/ha * 20

As mentioned above, many of these were not updated in 2022 and would need to be before they can be included in models to look at all 15 years.

I recalculate the confirmed and probable territory counts COBPRB to look at how well it correlates with survey detections using 2008-2018 data.  

```{r data}

det0 = data.frame(read.table("Pre2019detections.txt",
                             header=TRUE,
                             as.is=TRUE))
det = det0 %>%
  filter(ptd > -1, (is.na(note) | note != "presv")) %>%
  mutate(youngest = factor(youngest),
         COBPRB = CO + PR)

str(det)
summary(det)
table(det$Site)

dotchart(det$ha, main = "area (ha)")
dotchart(det$Age, main = "age")
dotchart(det$svdets, main = "survey detections")
dotchart(det$cha2, main = "contiguous area size")
dotchart(det$COBPRB, main = "counts of COB+PRB")


hist(det$ha, labels = TRUE, main = "area (ha)")
hist(det$Age, labels = TRUE, main = "age")
hist(det$cha2, labels = TRUE, main = "Continuous Ha")
hist(det$nAges, labels = TRUE, main = "nAges")
hist(det$COBPRB, labels = TRUE, main = "COBPRB")
boxplot(det$COBPRB)

pt19_sbsp = read.csv("pt19_sbsp.csv")[,-1]
pt20_sbsp = read.csv("pt20_sbsp.csv")[,-1]
pt21_sbsp = read.csv("pt21_sbsp.csv")[,-1]
pt22_sbsp = read.csv("pt22_sbsp.csv")[,-1]
```


## Matching up 2019-2022 data to older data

Cari Lynn developed a table to relate MSCP Section numbers to sites used in previous analyses called Transects2019_14Feb23.xls.  We add in some new sites here that were not surveyed before 2019.

The Trans19_sub is the data for just the SiteCodes in the 2018 analysis.  It gives a list of SurveyKeys that could be used to summarize data from pt19, pt20, pt21, and pt22.

```{r matching}

Transects2019_14Feb23 = read_excel("Transects2019_14Feb23.xls")

Trans19_sub = Transects2019_14Feb23 %>%
  rename(OldSite = Site,
         Site = notes) %>%
  separate("SurveyKey",
           c("year", "species","loccode1922"),
           extra = 'drop',
           remove = F) %>%
  select(-year, -species)

table(Trans19_sub$loccode1922)

codeconvert = Trans19_sub %>%
  select(Site, loccode1922) %>%
  distinct() %>%
  add_row(Site = "CNN160", loccode1922 = "C2740")

loccodes = c(unique(Trans19_sub$loccode1922), "C2740")

# Get variables from pre-2019 surveys and add in some for new sites
detvars = det %>%
  select(Site, Year, Age, contig, big, ha, cha, cha2, inc, youngest,
         nAges) %>%
  filter(Year == 2018) %>%
  select(-Year) %>%
# Add lines for new sites not in the pre-2019 data set. Age is 2018 age.
  add_row(Site = "CNHFM", Age = 1, ha = 49.26, 
          inc = 1) %>%
  add_row(Site = "CNHFN", Age = 5, ha = 37.86,
          inc = 1) %>%
  add_row(Site = "CVCA09", Age = 1, ha = 31.25,
          inc = 1) %>%
  add_row(Site = "CNN160", Age = 1, ha = 63.92,
          inc = 0) %>%
  mutate(Age19 = Age + 1,
         Age20 = Age + 2,
         Age21 = Age + 3,
         Age22 = Age + 4)
write.csv(detvars, "detectionvars.csv")

# Get the new data and reformat to match, 
#   including calculating age from old age data
pt19_det_by_site = pt19_sbsp %>%
  filter(loccode1922 %in% loccodes) %>%
  mutate(detections = rowSums(.[2:5])) %>%
  left_join(codeconvert) %>%
  select(loccode1922, detections, Site) %>%
  group_by(Site) %>%
  summarise(svdets = sum(detections)) %>%
  mutate(Year = 2019) %>%
  left_join(select(detvars, 
                   -c("Age", "Age20", "Age21", "Age22")),
                   by = "Site") %>%
  rename(Age = Age19) %>%
  mutate(dph = svdets / ha)

pt20_det_by_site = pt20_sbsp %>%
  filter(loccode1922 %in% loccodes) %>%
  mutate(detections = rowSums(.[2:5])) %>%
  left_join(codeconvert) %>%
  select(loccode1922, detections, Site) %>%
  group_by(Site)%>%
  summarise(svdets = sum(detections)) %>%
  mutate(Year = 2020) %>%
  left_join(select(detvars, 
                   -c("Age", "Age19", "Age21", "Age22")),
                   by = "Site") %>%
  rename(Age = Age20) %>%
  mutate(dph = svdets / ha)

pt21_det_by_site = pt21_sbsp %>%
  filter(loccode1922 %in% loccodes) %>%
  mutate(detections = rowSums(.[2:5])) %>%
  left_join(codeconvert) %>%
  select(loccode1922, detections, Site) %>%
  group_by(Site)%>%
  summarise(svdets = sum(detections)) %>%
  mutate(Year = 2021) %>%
  left_join(select(detvars, 
                   -c("Age", "Age19", "Age20", "Age22")),
                   by = "Site") %>%
  rename(Age = Age21) %>%
  mutate(dph = svdets / ha)

pt22_det_by_site = pt22_sbsp %>%
  filter(loccode1922 %in% loccodes) %>%
  mutate(detections = rowSums(.[2:5])) %>%
  left_join(codeconvert) %>%
  select(loccode1922, detections, Site) %>%
  group_by(Site)%>%
  summarise(svdets = sum(detections)) %>%
  mutate(Year = 2022) %>%
  left_join(select(detvars, 
                   -c("Age", "Age19", "Age20", "Age21")),
                   by = "Site") %>%
  rename(Age = Age22) %>%
  mutate(dph = svdets / ha)

det1922 = bind_rows(pt19_det_by_site, 
                    pt20_det_by_site,
                    pt21_det_by_site,
                    pt22_det_by_site)
detAll = bind_rows(det, det1922)
write.csv(detAll, "det_08_22.csv")

```

## Modeling detections

Since we did not count territories, I checked to see if svdets and COBPRB are correlated and they are highly correlated(r = 0.92).  If we want to predict territories from stand age, we can use the regression from the pre-2019 data.

Model 44 had overdispersed residuals, which indicated that a poisson model was inappropriate.  Rather than square root transform the detection counts as in the 2018 report, we just redid the model using negative binomial.

Area has a disjunct distribution (bimodal).  This caused problems with model convergence so we scale the area (ha) to a mean of zero with variance of +- 1 SD.

```{r detections}
plot(detAll$svdets, detAll$COBPRB)
cor.test(detAll$svdets, detAll$COBPRB)
detTerr.lm = lm(detAll$COBPRB~detAll$svdets)
summary(detTerr.lm)
abline(detTerr.lm)
# predictions between 1-102
detTerr.lm.pred = predict(detTerr.lm)

plot((detAll$svdets / detAll$ha), detAll$COBPRB)
cor.test((detAll$svdets / detAll$ha), detAll$COBPRB)
dphTerr.lm = lm(detAll$COBPRB~(detAll$svdets / detAll$ha))
summary(dphTerr.lm)
abline(dphTerr.lm)
# predictions between 1-102
dphTerr.lm.pred = predict(dphTerr.lm)

## Rerescaling of ha variable to improve model convergence below
detAll$ha1 = (detAll$ha - mean(detAll$ha)) / sd(detAll$ha)

#data visualization plot - AED functions used here
Z = cbind(detAll$svdets, # potential response variable
           detAll$dph, # potential response variable
           detAll$Year, # potential predictor variables
           detAll$ha, # potential predictor variables
           detAll$Age) # potential predictor variables
colnames(Z) = c("svdets", "dph", "Year", "ha", "Age")

# pairwise scatterplots and correlation coefficients to examine for colinearity
pairs(Z, lower.panel=panel.smooth2,upper.panel=panel.cor,diag.panel=panel.hist); 

# check for correlation and VIF - A VIF less than 3 is good. 
# Cannot include both of pair that are correlated 100% like cha2 and cha3
corvif(Z[,c(-1, -2, -6, -9)])   # from AED script file, gets correlation coefficients between pairs and VIF for each 

# Model ID numbers were kept the same for easier reference to bigger modeling methods
R46  = glmer.nb(svdets ~ Age +(1|Site)+(1|Year), data = detAll)
# this did not converge leading us to scale ha to mean of zero and 1 SD variance
R47  = glmer.nb(svdets ~ ha + Age + ha:Age +(1|Site)+(1|Year), data = detAll)
R48  = glmer.nb(svdets ~ ha1 + Age + ha1:Age +(1|Site)+(1|Year), data = detAll,)
R49  = glmer.nb(svdets ~ ha1 + (1|Site)+(1|Year), data = detAll)

models.nb = list("R48" = R48, "R49" = R49, "R46" = R46)

# Display a table of Model#, AIC, delta AIC, & Akaike wt
aictab(models.nb)

# Best model base don AIC comparison
summary(R48)

#Residuals look pretty good
qqnorm(residuals(R48))

#Overdispersion result from model 48: 1.148619; close to 1, so no overdispersion
E1nb <- residuals(R48)
p1nb <- length(fixef(R48)) + 1
(Overdisp1nb <- sum(E1nb^2) / (nrow(detAll) - p1nb))

#Checking for Deviance Residual GOF, a check for overdispersion
(phinb <- sum(resid(R48, type = "pearson")^2) / df.residual(R48))
# 0.9230442 -  data is not overdispersed

#Residual diagnostic plots
op <- par(mfrow=c(2,3),mar=c(5,4,1,2))
E<-resid(R48)
fit <-fitted(R48)
hist(E,xlab="Residuals",main="")   #histogram to check for normality
qqnorm(E)                           #QQ plot to check for normality
plot(fit,E, main="Residuals vs. Fitted Values", ylab="Residual", xlab="Fitted values")    #fitted vs residuals to check homogenaity/heteroskedacity - look for patterns
plot(detAll$ha,E,xlab="ha",ylab="Residuals")                  #residuals vs each explanatory variable to check for independence
plot(detAll$Age,E,xlab="age",ylab="Residuals")                #residuals vs each explanatory variable to check for independence
# plot(detAll$nAge,E,xlab="n age",ylab="Residuals")             #residuals vs each explanatory variable to check for independence
par(op)

# Looking at the various intercept values for random effect variables
coef(R48)
coefs <-coef(R48)$Site[,"(Intercept)"]
plot(coefs)
boxplot(coefs)

coefs <-coef(R48)$Year[,"(Intercept)"]
plot(coefs)
boxplot(coefs)

plot_model(R48, 
           type = "pred", 
           terms = c("Age", "ha1"),
           legend.title = "Area (scaled)",
           axis.title = c("Age (years since planting)", "Survey detections"))
plot_model(R48, 
           type = "pred", colors = "bw",
           terms = c("Age", "ha1"),
           legend.title = "Area (scaled)",
           axis.title = c("Age (years since planting)", "Survey detections"))

# backtransform ha1 for plot
descale_ha = function(x){
  x * sd(detAll$ha) + mean(detAll$ha)
}

pretty = (c(20,50,80) - mean(detAll$ha)) / sd(detAll$ha)

p = plot_model(R48, 
           type = "pred", colors = "bw",
           terms = c("Age", 
                     "ha1[-0.8382141, 0.4280929, 1.6944]"),
           title = "Survey Detections by Site Age/Size",
           legend.title = "Area (ha)",
           axis.title = c("Age (years since planting)", "Survey detections"))

p = p + scale_linetype_manual(
  values = c(1:3),
  labels = c("20", "50","80"))
p
ggsave(path =
         "LCR_YBCU_DetectionModelFinalReport",
       "svdets_age_effects_plot_bw.jpg",
       width = 7, height = 3.5, units = "in")
```

